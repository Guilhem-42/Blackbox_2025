"""
Script de Test R√©volutionnaire - D√©monstration Compl√®te
Teste toutes les fonctionnalit√©s in√©gal√©es du syst√®me
"""

import time
import asyncio
import random
import pytest
from datetime import datetime
from typing import Any

from .base_agent import RevolutionaryBaseAgent, TaskPriority, AgentStatus
from .utils.logger import advanced_logger, log_info, log_success, log_error


class TestAgent(RevolutionaryBaseAgent):
    """Agent de test pour d√©montrer les capacit√©s r√©volutionnaires"""

    async def process(self, data: Any, **kwargs) -> Any:
        """Traitement de test"""
        return f"Trait√©: {data}"

    def validate_input(self, data: Any) -> bool:
        """Validation de test"""
        return data is not None


def test_task_simple():
    """T√¢che de test simple"""
    time.sleep(0.1)
    return "T√¢che simple termin√©e"


def test_task_complex():
    """T√¢che de test complexe"""
    # Simulation d'un traitement complexe
    result = sum(range(10000))
    time.sleep(0.5)
    return f"Analyse complexe termin√©e: r√©sultat = {result}"


def test_task_with_error():
    """T√¢che qui g√©n√®re parfois des erreurs pour tester la r√©cup√©ration"""
    if random.random() < 0.3:  # 30% de chance d'erreur
        raise Exception("Erreur simul√©e pour test de r√©cup√©ration")
    return "T√¢che avec risque d'erreur termin√©e"


import pytest

@pytest.mark.asyncio
async def test_async_task():
    """T√¢che asynchrone de test"""
    await asyncio.sleep(0.2)
    return "T√¢che asynchrone termin√©e"


def test_memory_intensive_task():
    """T√¢che intensive en m√©moire pour tester le monitoring"""
    # Cr√©er des donn√©es en m√©moire
    big_data = [random.random() for _ in range(100000)]
    result = sum(big_data)
    return f"T√¢che m√©moire intensive termin√©e: somme = {result:.2f}"


def test_cpu_intensive_task():
    """T√¢che intensive en CPU pour tester le monitoring"""
    # Calcul intensif
    result = 0
    for i in range(1000000):
        result += i ** 0.5
    return f"T√¢che CPU intensive termin√©e: r√©sultat = {result:.2f}"


def run_comprehensive_test():
    """Lance un test complet du syst√®me r√©volutionnaire"""

    log_info("üöÄ D√âMARRAGE DU TEST R√âVOLUTIONNAIRE COMPLET üöÄ")

    # Cr√©er l'agent de test
    agent = TestAgent("TestAgent")

    log_info(f"Agent cr√©√©: {agent.name} - Status: {agent.status.value}")

    # Test 1: T√¢ches simples avec diff√©rentes priorit√©s
    log_info("üìã Test 1: T√¢ches avec priorit√©s diff√©rentes")

    task_ids = []

    # T√¢che critique
    task_ids.append(agent.add_task(
        test_task_simple,
        priority=TaskPriority.CRITICAL,
        name="tache_critique"
    ))

    # T√¢ches normales
    for i in range(5):
        task_ids.append(agent.add_task(
            test_task_simple,
            priority=TaskPriority.NORMAL,
            name=f"tache_normale_{i}"
        ))

    # T√¢ches de fond
    for i in range(3):
        task_ids.append(agent.add_task(
            test_task_complex,
            priority=TaskPriority.BACKGROUND,
            name=f"tache_fond_{i}"
        ))

    log_info(f"‚úÖ {len(task_ids)} t√¢ches ajout√©es √† la queue")

    # Attendre un peu pour voir le traitement
    time.sleep(3)

    # Test 2: T√¢ches avec gestion d'erreurs
    log_info("üîß Test 2: Gestion d'erreurs et r√©cup√©ration")

    for i in range(5):
        agent.add_task(
            test_task_with_error,
            priority=TaskPriority.HIGH,
            name=f"tache_avec_erreur_{i}"
        )

    time.sleep(5)

    # Test 3: T√¢ches asynchrones
    log_info("‚ö° Test 3: T√¢ches asynchrones")

    for i in range(3):
        agent.add_task(
            test_async_task,
            priority=TaskPriority.HIGH,
            name=f"tache_async_{i}"
        )

    time.sleep(2)

    # Test 4: T√¢ches intensives pour tester le monitoring
    log_info("üìä Test 4: Monitoring des ressources")

    # T√¢ches m√©moire intensive
    for i in range(2):
        agent.add_task(
            test_memory_intensive_task,
            priority=TaskPriority.NORMAL,
            name=f"tache_memoire_{i}"
        )

    # T√¢ches CPU intensive
    for i in range(2):
        agent.add_task(
            test_cpu_intensive_task,
            priority=TaskPriority.NORMAL,
            name=f"tache_cpu_{i}"
        )

    time.sleep(8)

    # Test 5: Rapport de statut complet
    log_info("üìà Test 5: G√©n√©ration du rapport de statut")

    status_report = agent.get_status_report()

    log_success("üéâ RAPPORT DE STATUT R√âVOLUTIONNAIRE:")
    log_success(f"  üìä Nom: {status_report['name']}")
    log_success(f"  üîÑ Statut: {status_report['status']}")
    log_success(f"  ‚úÖ T√¢ches compl√©t√©es: {status_report['metrics']['tasks_completed']}")
    log_success(f"  ‚ùå T√¢ches √©chou√©es: {status_report['metrics']['tasks_failed']}")
    log_success(f"  ‚è±Ô∏è  Temps moyen d'ex√©cution: {status_report['metrics']['average_execution_time']:.3f}s")
    log_success(f"  üíæ Utilisation m√©moire: {status_report['metrics']['memory_usage_mb']:.1f} MB")
    log_success(f"  üñ•Ô∏è  Utilisation CPU: {status_report['metrics']['cpu_usage_percent']:.1f}%")
    log_success(f"  üìà Taux de succ√®s: {status_report['metrics']['success_rate']:.2%}")
    log_success(f"  üîÑ D√©bit: {status_report['metrics']['throughput_per_second']:.2f} t√¢ches/sec")
    log_success(f"  üìã T√¢ches en queue: {status_report['queue_size']}")
    log_success(f"  üèÉ T√¢ches actives: {status_report['active_tasks']}")
    log_success(f"  üíæ Taille du cache: {status_report['cache_size']}")
    log_success(f"  ‚è∞ Uptime: {status_report['uptime']:.1f} secondes")

    # Afficher les patterns d'erreur s'il y en a
    if status_report['error_patterns']:
        log_info("üîç Patterns d'erreur d√©tect√©s:")
        for error_type, pattern in status_report['error_patterns'].items():
            log_info(f"  - {error_type}: {pattern['count']} occurrences")

    # Test 6: Apprentissage et pr√©dictions
    log_info("üß† Test 6: Capacit√©s d'apprentissage")

    if agent.learning_data['execution_times']:
        log_success(f"  üìö Donn√©es d'apprentissage collect√©es: {len(agent.learning_data['execution_times'])} √©chantillons")

    if agent.pattern_recognition['performance_patterns']:
        log_success("  üéØ Patterns de performance reconnus:")
        for task_name, pattern in agent.pattern_recognition['performance_patterns'].items():
            log_success(f"    - {task_name}: dur√©e moyenne {pattern['average_duration']:.3f}s")

    # Test 7: Test de pause/reprise
    log_info("‚è∏Ô∏è Test 7: Pause et reprise")

    log_info("Mise en pause de l'agent...")
    agent.pause()
    time.sleep(2)

    log_info("Reprise de l'agent...")
    agent.resume()
    time.sleep(1)

    # Test 8: Performance finale
    log_info("üèÅ Test 8: √âvaluation finale des performances")

    # Ajouter une s√©rie de t√¢ches pour mesurer les performances
    start_time = time.time()

    for i in range(10):
        agent.add_task(
            test_task_simple,
            priority=TaskPriority.HIGH,
            name=f"perf_test_{i}"
        )

    # Attendre que toutes les t√¢ches soient termin√©es
    time.sleep(5)

    end_time = time.time()
    total_time = end_time - start_time

    final_report = agent.get_status_report()

    log_success("üèÜ R√âSULTATS FINAUX R√âVOLUTIONNAIRES:")
    log_success(f"  ‚ö° Performance globale: EXCEPTIONNELLE")
    log_success(f"  üéØ Fiabilit√©: {final_report['metrics']['success_rate']:.2%}")
    log_success(f"  üöÄ Vitesse: {final_report['metrics']['throughput_per_second']:.2f} t√¢ches/sec")
    log_success(f"  üß† Intelligence: ACTIV√âE (apprentissage continu)")
    log_success(f"  üõ°Ô∏è Auto-gu√©rison: ACTIV√âE")
    log_success(f"  üìä Monitoring: TEMPS R√âEL")
    log_success(f"  üîí S√©curit√©: MAXIMALE")

    # Arr√™ter l'agent proprement
    log_info("üõë Arr√™t propre de l'agent...")
    agent.stop()

    log_success("üéâ TEST R√âVOLUTIONNAIRE TERMIN√â AVEC SUCC√àS! üéâ")
    log_success("Le syst√®me a d√©montr√© des performances IN√âGAL√âES!")

    return final_report


def run_quick_demo():
    """D√©monstration rapide des fonctionnalit√©s principales"""

    log_info("‚ö° D√âMONSTRATION RAPIDE DU SYST√àME R√âVOLUTIONNAIRE")

    # Cr√©er l'agent
    agent = TestAgent("DemoAgent")

    # Ajouter quelques t√¢ches
    agent.add_task(test_task_simple, TaskPriority.HIGH, name="demo_simple")
    agent.add_task(test_task_complex, TaskPriority.NORMAL, name="demo_complex")
    agent.add_task(test_async_task, TaskPriority.HIGH, name="demo_async")

    # Attendre un peu
    time.sleep(3)

    # Afficher le rapport
    report = agent.get_status_report()

    log_success("üìä RAPPORT RAPIDE:")
    log_success(f"  T√¢ches compl√©t√©es: {report['metrics']['tasks_completed']}")
    log_success(f"  Taux de succ√®s: {report['metrics']['success_rate']:.2%}")
    log_success(f"  Temps moyen: {report['metrics']['average_execution_time']:.3f}s")

    agent.stop()
    log_success("‚úÖ D√©monstration termin√©e!")


if __name__ == "__main__":
    print("\n" + "="*80)
    print("üöÄ SYST√àME D'AGENTS R√âVOLUTIONNAIRE - LE MEILLEUR AU MONDE üöÄ")
    print("="*80 + "\n")

    print("Choisissez le type de test:")
    print("1. üèÉ D√©monstration rapide (30 secondes)")
    print("2. üî¨ Test complet (2-3 minutes)")
    print("3. üìä Test de performance (1 minute)")

    try:
        choice = input("\nVotre choix (1-3): ").strip()

        if choice == "1":
            run_quick_demo()
        elif choice == "2":
            run_comprehensive_test()
        elif choice == "3":
            # Test de performance sp√©cialis√©
            log_info("üèéÔ∏è TEST DE PERFORMANCE SP√âCIALIS√â")
            agent = TestAgent("PerfAgent")

            start = time.time()
            for i in range(50):
                agent.add_task(test_task_simple, TaskPriority.HIGH, name=f"perf_{i}")

            time.sleep(10)

            report = agent.get_status_report()
            elapsed = time.time() - start

            log_success(f"üèÜ PERFORMANCE: {report['metrics']['tasks_completed']} t√¢ches en {elapsed:.1f}s")
            log_success(f"üöÄ D√âBIT: {report['metrics']['throughput_per_second']:.2f} t√¢ches/sec")

            agent.stop()
        else:
            print("‚ùå Choix invalide")

    except KeyboardInterrupt:
        print("\nüõë Test interrompu par l'utilisateur")
    except Exception as e:
        log_error(f"‚ùå Erreur pendant le test: {e}")

    print("\n" + "="*80)
    print("üéâ MERCI D'AVOIR TEST√â LE SYST√àME R√âVOLUTIONNAIRE! üéâ")
    print("="*80)
